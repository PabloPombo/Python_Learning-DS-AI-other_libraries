{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0567647c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\pablo\\anaconda3\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pablo\\anaconda3\\lib\\site-packages (from sqlalchemy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install boto3\n",
    "#!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# üîß CONFIGURACI√ìN\n",
    "\n",
    "AWS_ACCESS_KEY = 'TU_ACCESS_KEY'\n",
    "AWS_SECRET_KEY = 'TU_SECRET_KEY'\n",
    "BUCKET_NAME = 'tu-bucket'\n",
    "S3_PREFIX = 'datos/'  # Ruta en el bucket donde est√°n los CSV\n",
    "LOCAL_FOLDER = 'tmp_s3_files'\n",
    "\n",
    "# Datos de conexi√≥n a MySQL\n",
    "DB_USER = 'usuario_mysql'\n",
    "DB_PASSWORD = 'clave_mysql'\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '3306'\n",
    "DB_NAME = 'mi_base'\n",
    "DB_TABLE = 'ventas'\n",
    "\n",
    "# Crear carpeta local para guardar los archivos descargados\n",
    "os.makedirs(LOCAL_FOLDER, exist_ok=True)\n",
    "\n",
    "# Crear motor SQLAlchemy para MySQL\n",
    "engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "# Conectar a S3\n",
    "s3 = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)\n",
    "\n",
    "# Listar archivos .csv en el bucket\n",
    "response = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=S3_PREFIX)\n",
    "\n",
    "for obj in response.get('Contents', []):\n",
    "    key = obj['Key']\n",
    "    if key.endswith('.csv'):\n",
    "        filename = key.split('/')[-1]\n",
    "        local_path = os.path.join(LOCAL_FOLDER, filename)\n",
    "\n",
    "        # Evitar re-descargar si ya est√°\n",
    "        if not os.path.exists(local_path):\n",
    "            print(f\"üì• Descargando {filename}...\")\n",
    "            s3.download_file(BUCKET_NAME, key, local_path)\n",
    "\n",
    "            try:\n",
    "                # Leer CSV\n",
    "                df = pd.read_csv(local_path)\n",
    "\n",
    "                # Agregar columna de fecha de carga (opcional)\n",
    "                df['fecha_carga'] = datetime.now()\n",
    "\n",
    "                # Cargar a MySQL\n",
    "                df.to_sql(DB_TABLE, engine, if_exists='append', index=False)\n",
    "                print(f\"‚úÖ {filename} cargado en MySQL.\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error procesando {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa180548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#En Linux para que se corra cada 5 \n",
    "\n",
    "# */5 * * * * /usr/bin/python3 /ruta/script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b68b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# CONFIGURACI√ìN\n",
    "AWS_ACCESS_KEY = 'TU_ACCESS_KEY'\n",
    "AWS_SECRET_KEY = 'TU_SECRET_KEY'\n",
    "BUCKET_NAME = 'tu-bucket'\n",
    "S3_PREFIX = 'datos/'\n",
    "LOCAL_FOLDER = 'tmp_s3_files'\n",
    "PROCESADOS_FILE = 'procesados.txt'\n",
    "\n",
    "# Base de datos MySQL\n",
    "DB_USER = 'usuario_mysql'\n",
    "DB_PASSWORD = 'clave_mysql'\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '3306'\n",
    "DB_NAME = 'mi_base'\n",
    "DB_TABLE = 'ventas'\n",
    "CAMPO_CLAVE = 'id'  # Cambia esto por el campo que identifique registros √∫nicos\n",
    "\n",
    "# Crear carpeta y archivo de control\n",
    "os.makedirs(LOCAL_FOLDER, exist_ok=True)\n",
    "if not os.path.exists(PROCESADOS_FILE):\n",
    "    open(PROCESADOS_FILE, 'w').close()\n",
    "\n",
    "# Cargar lista de archivos ya procesados\n",
    "with open(PROCESADOS_FILE, 'r') as f:\n",
    "    archivos_procesados = set(line.strip() for line in f)\n",
    "\n",
    "# Conexiones\n",
    "engine = create_engine(f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "s3 = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)\n",
    "\n",
    "# Descargar archivos nuevos\n",
    "response = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=S3_PREFIX)\n",
    "\n",
    "for obj in response.get('Contents', []):\n",
    "    key = obj['Key']\n",
    "    if key.endswith('.csv'):\n",
    "        filename = key.split('/')[-1]\n",
    "\n",
    "        if filename in archivos_procesados:\n",
    "            print(f\"‚è© Ya procesado: {filename}\")\n",
    "            continue\n",
    "\n",
    "        local_path = os.path.join(LOCAL_FOLDER, filename)\n",
    "        print(f\"üì• Descargando: {filename}\")\n",
    "        s3.download_file(BUCKET_NAME, key, local_path)\n",
    "\n",
    "        try:\n",
    "            # Leer CSV\n",
    "            df = pd.read_csv(local_path)\n",
    "            df['fecha_carga'] = datetime.now()\n",
    "\n",
    "            # Verificar duplicados\n",
    "            if CAMPO_CLAVE in df.columns:\n",
    "                # Obtener claves ya presentes en BD\n",
    "                with engine.connect() as conn:\n",
    "                    existing = pd.read_sql(f\"SELECT {CAMPO_CLAVE} FROM {DB_TABLE}\", conn)\n",
    "                claves_existentes = set(existing[CAMPO_CLAVE].astype(str))\n",
    "\n",
    "                # Filtrar registros nuevos\n",
    "                df = df[~df[CAMPO_CLAVE].astype(str).isin(claves_existentes)]\n",
    "\n",
    "                if df.empty:\n",
    "                    print(f\"üö´ Todos los registros ya existen en {DB_TABLE}.\")\n",
    "                else:\n",
    "                    df.to_sql(DB_TABLE, engine, if_exists='append', index=False)\n",
    "                    print(f\"‚úÖ {len(df)} registros insertados desde {filename}.\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è El archivo {filename} no contiene la columna clave '{CAMPO_CLAVE}'.\")\n",
    "\n",
    "            # Guardar el nombre del archivo como procesado\n",
    "            with open(PROCESADOS_FILE, 'a') as f:\n",
    "                f.write(f\"{filename}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error procesando {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a719e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cacdd764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#engine = create_engine('mysql+pymysql://usuario:contrase√±a@host:puerto/nombre_basedatos')\n",
    "\n",
    "# Ejemplo real\n",
    "engine = create_engine('mysql+pymysql://root:PPOMBO@localhost:3306/empresadb')\n",
    "\n",
    "query = \"SELECT e.nombre AS Nombre, e.apellido AS Apellido, SUM(asi.horas_asignadas) AS 'Total Horas Trabajadas', RANK()OVER(PARTITION BY e.depto_id ORDER BY SUM(asi.horas_asignadas) DESC)AS 'Ranking Departamental' FROM Empleados AS e LEFT JOIN AsignacionesDeProyectos AS asi ON asi.empleado_id = e.empleado_id JOIN Departamentos AS d ON e.depto_id = d.depto_id GROUP BY e.empleado_id;\"\n",
    "\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "df.to_sql('tabla_python', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed7ef2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
